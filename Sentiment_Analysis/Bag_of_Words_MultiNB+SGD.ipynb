{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 25000 labeled train data, 50000 unlabeled train data and 25000 test data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv(\"/Users/shichangtai/Desktop/Kaggle/Bag of Wprds Meet Bags of Popcorn/labeledTrainData.tsv\",header=0,delimiter='\\t',quoting=3)\n",
    "test=pd.read_csv(\"/Users/shichangtai/Desktop/Kaggle/Bag of Wprds Meet Bags of Popcorn/testData.tsv\",header=0,delimiter='\\t',quoting=3)\n",
    "unlabeled_train=pd.read_csv(\"/Users/shichangtai/Desktop/Kaggle/Bag of Wprds Meet Bags of Popcorn/unlabeledTrainData.tsv\",header=0,delimiter='\\t',quoting=3)\n",
    "print(\"Load %d labeled train data, %d unlabeled train data and %d test data\" % (train[\"review\"].size, unlabeled_train[\"review\"].size, len(test['review'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def review_to_words(raw_review,remove_stopwords=False):\n",
    "    #1. remove html\n",
    "    raw_text=BeautifulSoup(raw_review,'lxml').get_text()\n",
    "    #2. remove non-letter, replace n't (maybe we can hold the number)\n",
    "    only_letter_text=re.sub(\"\\d\",\"NUM\",raw_text)\n",
    "    only_letter_text=re.sub(\"n\\'t\",\" not\",only_letter_text)\n",
    "    only_letter_text=re.sub(\"[^a-zA-Z]\",\" \",only_letter_text)\n",
    "    #3. split and lower case\n",
    "    pure_text=only_letter_text.lower().split()\n",
    "    #4. (optional) remove stop words\n",
    "    if remove_stopwords:\n",
    "        stemmer=nltk.PorterStemmer()\n",
    "        stopword=set(stopwords.words(\"english\"))\n",
    "        pure_text=[stemmer(m) for m in pure_text if m not in stopword]\n",
    "    #5. return a list of words\n",
    "    return (\" \".join(pure_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "def review_to_sentences(review,tokenizer,remove_stopwords=False):\n",
    "    sentences=[]\n",
    "    raw_sentences=tokenizer.tokenize(review.strip())\n",
    "    for item in raw_sentences:\n",
    "        if(len(item)>0):\n",
    "            sentences.append(review_to_words(item,remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set movie reviews...\n",
      "\n",
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n",
      "Review 6000 of 25000\n",
      "\n",
      "Review 7000 of 25000\n",
      "\n",
      "Review 8000 of 25000\n",
      "\n",
      "Review 9000 of 25000\n",
      "\n",
      "Review 10000 of 25000\n",
      "\n",
      "Review 11000 of 25000\n",
      "\n",
      "Review 12000 of 25000\n",
      "\n",
      "Review 13000 of 25000\n",
      "\n",
      "Review 14000 of 25000\n",
      "\n",
      "Review 15000 of 25000\n",
      "\n",
      "Review 16000 of 25000\n",
      "\n",
      "Review 17000 of 25000\n",
      "\n",
      "Review 18000 of 25000\n",
      "\n",
      "Review 19000 of 25000\n",
      "\n",
      "Review 20000 of 25000\n",
      "\n",
      "Review 21000 of 25000\n",
      "\n",
      "Review 22000 of 25000\n",
      "\n",
      "Review 23000 of 25000\n",
      "\n",
      "Review 24000 of 25000\n",
      "\n",
      "Review 25000 of 25000\n",
      "\n",
      "Cleaning and parsing the unlabeled_train set movie reviews...\n",
      "\n",
      "Review 1000 of 50000\n",
      "\n",
      "Review 2000 of 50000\n",
      "\n",
      "Review 3000 of 50000\n",
      "\n",
      "Review 4000 of 50000\n",
      "\n",
      "Review 5000 of 50000\n",
      "\n",
      "Review 6000 of 50000\n",
      "\n",
      "Review 7000 of 50000\n",
      "\n",
      "Review 8000 of 50000\n",
      "\n",
      "Review 9000 of 50000\n",
      "\n",
      "Review 10000 of 50000\n",
      "\n",
      "Review 11000 of 50000\n",
      "\n",
      "Review 12000 of 50000\n",
      "\n",
      "Review 13000 of 50000\n",
      "\n",
      "Review 14000 of 50000\n",
      "\n",
      "Review 15000 of 50000\n",
      "\n",
      "Review 16000 of 50000\n",
      "\n",
      "Review 17000 of 50000\n",
      "\n",
      "Review 18000 of 50000\n",
      "\n",
      "Review 19000 of 50000\n",
      "\n",
      "Review 20000 of 50000\n",
      "\n",
      "Review 21000 of 50000\n",
      "\n",
      "Review 22000 of 50000\n",
      "\n",
      "Review 23000 of 50000\n",
      "\n",
      "Review 24000 of 50000\n",
      "\n",
      "Review 25000 of 50000\n",
      "\n",
      "Review 26000 of 50000\n",
      "\n",
      "Review 27000 of 50000\n",
      "\n",
      "Review 28000 of 50000\n",
      "\n",
      "Review 29000 of 50000\n",
      "\n",
      "Review 30000 of 50000\n",
      "\n",
      "Review 31000 of 50000\n",
      "\n",
      "Review 32000 of 50000\n",
      "\n",
      "Review 33000 of 50000\n",
      "\n",
      "Review 34000 of 50000\n",
      "\n",
      "Review 35000 of 50000\n",
      "\n",
      "Review 36000 of 50000\n",
      "\n",
      "Review 37000 of 50000\n",
      "\n",
      "Review 38000 of 50000\n",
      "\n",
      "Review 39000 of 50000\n",
      "\n",
      "Review 40000 of 50000\n",
      "\n",
      "Review 41000 of 50000\n",
      "\n",
      "Review 42000 of 50000\n",
      "\n",
      "Review 43000 of 50000\n",
      "\n",
      "Review 44000 of 50000\n",
      "\n",
      "Review 45000 of 50000\n",
      "\n",
      "Review 46000 of 50000\n",
      "\n",
      "Review 47000 of 50000\n",
      "\n",
      "Review 48000 of 50000\n",
      "\n",
      "Review 49000 of 50000\n",
      "\n",
      "Review 50000 of 50000\n",
      "\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n",
      "Review 6000 of 25000\n",
      "\n",
      "Review 7000 of 25000\n",
      "\n",
      "Review 8000 of 25000\n",
      "\n",
      "Review 9000 of 25000\n",
      "\n",
      "Review 10000 of 25000\n",
      "\n",
      "Review 11000 of 25000\n",
      "\n",
      "Review 12000 of 25000\n",
      "\n",
      "Review 13000 of 25000\n",
      "\n",
      "Review 14000 of 25000\n",
      "\n",
      "Review 15000 of 25000\n",
      "\n",
      "Review 16000 of 25000\n",
      "\n",
      "Review 17000 of 25000\n",
      "\n",
      "Review 18000 of 25000\n",
      "\n",
      "Review 19000 of 25000\n",
      "\n",
      "Review 20000 of 25000\n",
      "\n",
      "Review 21000 of 25000\n",
      "\n",
      "Review 22000 of 25000\n",
      "\n",
      "Review 23000 of 25000\n",
      "\n",
      "Review 24000 of 25000\n",
      "\n",
      "Review 25000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_reviews=len(train[\"review\"])\n",
    "print(\"Cleaning and parsing the training set movie reviews...\\n\")\n",
    "clean_train_reviews=[]\n",
    "for x in xrange(0,num_reviews):\n",
    "    if((x+1)%1000==0):\n",
    "        print (\"Review %d of %d\\n\" % (x+1,num_reviews))\n",
    "    clean_train_reviews.append(review_to_words(train[\"review\"][x]))\n",
    "\n",
    "num_reviews=len(unlabeled_train[\"review\"])\n",
    "print(\"Cleaning and parsing the unlabeled_train set movie reviews...\\n\")\n",
    "unlabeled_clean_train_reviews=[]\n",
    "for x in xrange(0,num_reviews):\n",
    "    if((x+1)%1000==0):\n",
    "        print (\"Review %d of %d\\n\" % (x+1,num_reviews))\n",
    "    unlabeled_clean_train_reviews.append(review_to_words(unlabeled_train[\"review\"][x]))\n",
    "    \n",
    "num_reviews=len(test[\"review\"])\n",
    "print(\"Cleaning and parsing the test set movie reviews...\\n\")\n",
    "clean_test_reviews=[]\n",
    "for x in xrange(0,num_reviews):\n",
    "    if((x+1)%1000==0):\n",
    "        print (\"Review %d of %d\\n\" % (x+1,num_reviews))\n",
    "    clean_test_reviews.append(review_to_words(test[\"review\"][x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Training...\n",
      "Writing results...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "print \"Vectorizing...\"\n",
    "\n",
    "vectorizer = TfidfVectorizer( min_df=2, max_df=0.95, max_features = 50000, ngram_range = ( 1, 4 ),\n",
    "                              sublinear_tf = True )\n",
    "\n",
    "vectorizer = vectorizer.fit(clean_train_reviews + unlabeled_clean_train_reviews)\n",
    "train_data_features = vectorizer.transform( clean_train_reviews )\n",
    "test_data_features = vectorizer.transform( clean_test_reviews )\n",
    "\n",
    "#print \"Reducing dimension...\"\n",
    "\n",
    "#from sklearn.feature_selection.univariate_selection import SelectKBest, chi2, f_classif\n",
    "#fselect = SelectKBest(chi2 , k=40000)\n",
    "#train_data_features = fselect.fit_transform(train_data_features, train[\"sentiment\"])\n",
    "#test_data_features = fselect.transform(test_data_features)\n",
    "\n",
    "print \"Training...\"\n",
    "\n",
    "model1 = MultinomialNB(alpha=0.0005)\n",
    "model1.fit( train_data_features, train[\"sentiment\"] )\n",
    "\n",
    "model2 = SGDClassifier(loss='modified_huber', n_iter=5, random_state=0, shuffle=True)\n",
    "model2.fit( train_data_features, train[\"sentiment\"] )\n",
    "\n",
    "p1 = model1.predict_proba( test_data_features )[:,1]\n",
    "p2 = model2.predict_proba( test_data_features )[:,1]\n",
    "\n",
    "print \"Writing results...\"\n",
    "\n",
    "output = pd.DataFrame( data = { \"id\": test[\"id\"], \"sentiment\": .2*p1 + 1.*p2 } )\n",
    "output.to_csv(\"/Users/shichangtai/Desktop/Kaggle/Bag of Wprds Meet Bags of Popcorn/result_Combine_BagOfWords.csv\",index=False,quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# amazing 0.96699!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
