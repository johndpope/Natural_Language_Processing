{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import cross_validation, metrics\n",
    "from memn2n import Memn2n\n",
    "from load_data import load_data_from_file, convert_data_to_number_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.flags.DEFINE_integer(\"task_id\", 1, \"bAbI task id, 1 <= id <= 20\")\n",
    "tf.flags.DEFINE_string(\"data_dir\", \"tasks_1-20_v1-2/en/\", \"Directory containing bAbI tasks\")\n",
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (900, 56, 10)\n",
      "Training size: 900\n",
      "Validation size: 100\n",
      "Testing size: 1000\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "epsilon=1e-8\n",
    "max_grad_norm=40.0\n",
    "batch_size=32\n",
    "hops=3\n",
    "epochs=100\n",
    "embedding_size=20\n",
    "memory_size=50\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate,epsilon=epsilon)\n",
    "\n",
    "\n",
    "def story_to_sentences(story_list):\n",
    "    sent=[]\n",
    "    for item in story_list:\n",
    "        sent+=item\n",
    "    return sent\n",
    "\n",
    "train,test=load_data_from_file(FLAGS.data_dir,FLAGS.task_id)\n",
    "all_data=train+test\n",
    "vocabulary=reduce(lambda x,y:x|y, (set(story_to_sentences(s)+q+a) for s,q,a in all_data))\n",
    "vocabulary=sorted(vocabulary)\n",
    "word_num=dict((word,index+1) for index,word in enumerate(vocabulary))\n",
    "\n",
    "vocabulary_size=len(word_num)+1\n",
    "max_story_size=max(map(len, (s for s,_,_ in all_data)))\n",
    "max_query_size=max(map(len, (q for _,q,_ in all_data)))\n",
    "max_sentence_size=max(map(len, (story_to_sentences(s) for s,_,_ in all_data)))\n",
    "max_sentence_size=max(max_sentence_size,max_query_size)\n",
    "max_memory_size=min(max_story_size,memory_size)\n",
    "\n",
    "#train_validation_test_split\n",
    "story,query,answer=convert_data_to_number_list(train,word_num,max_sentence_size,max_memory_size)\n",
    "story=np.transpose(story,[0,2,1])\n",
    "train_s,val_s,train_q,val_q,train_a,val_a=cross_validation.train_test_split(story,query,answer,test_size=0.1)\n",
    "test_s,test_q,test_a=convert_data_to_number_list(test,word_num,max_sentence_size,max_memory_size)\n",
    "\n",
    "test_s=np.transpose(test_s,[0,2,1])\n",
    "\n",
    "print(\"Shape of training data: \"+str(train_s.shape))\n",
    "print(\"Training size: \"+str(train_s.shape[0]))\n",
    "print(\"Validation size: \"+str(val_s.shape[0]))\n",
    "print(\"Testing size: \"+str(test_s.shape[0]))\n",
    "\n",
    "train_answer_label=np.argmax(train_a,1)\n",
    "validation_answer_label=np.argmax(val_a,1)\n",
    "test_answer_label=np.argmax(test_a,1)\n",
    "\n",
    "#set the start and end batch index\n",
    "batch_index=zip(range(0,train_s.shape[0]-batch_size,batch_size),range(batch_size,train_s.shape[0],batch_size))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sample=([['sandra','got','the','milk'],['sandra','went','to','office'],['mary','went','to','bedroom'],['sandra','moved','to','kitchen']],['where','was','the','milk'],['kitchen'])\n",
    "#sample_s,sample_q,sample_a=convert_data_to_number_list([sample],word_num,max_sentence_size,max_memory_size)\n",
    "#result=[x[0] for x in word_num.items() if x[1]==list(sample_a[0]).index(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------***********-----------------------\n",
      "This is epoch: 1 !\n",
      "Train accuracy rate is: 0.172222222222\n",
      "Validation accuracy rate is: 0.22\n",
      "The sum of training loss is: 1931.03199387\n",
      "------------------***********-----------------------\n",
      "This is epoch: 11 !\n",
      "Train accuracy rate is: 0.801111111111\n",
      "Validation accuracy rate is: 0.72\n",
      "The sum of training loss is: 634.978572845\n",
      "------------------***********-----------------------\n",
      "This is epoch: 21 !\n",
      "Train accuracy rate is: 0.992222222222\n",
      "Validation accuracy rate is: 0.95\n",
      "The sum of training loss is: 73.1768645942\n",
      "------------------***********-----------------------\n",
      "This is epoch: 31 !\n",
      "Train accuracy rate is: 0.996666666667\n",
      "Validation accuracy rate is: 1.0\n",
      "The sum of training loss is: 4.47316182498\n",
      "------------------***********-----------------------\n",
      "This is epoch: 41 !\n",
      "Train accuracy rate is: 0.996666666667\n",
      "Validation accuracy rate is: 1.0\n",
      "The sum of training loss is: 17.7311758511\n",
      "------------------***********-----------------------\n",
      "This is epoch: 51 !\n",
      "Train accuracy rate is: 0.994444444444\n",
      "Validation accuracy rate is: 0.98\n",
      "The sum of training loss is: 10.6355630327\n",
      "------------------***********-----------------------\n",
      "This is epoch: 61 !\n",
      "Train accuracy rate is: 0.993333333333\n",
      "Validation accuracy rate is: 1.0\n",
      "The sum of training loss is: 0.643878439441\n",
      "------------------***********-----------------------\n",
      "This is epoch: 71 !\n",
      "Train accuracy rate is: 0.993333333333\n",
      "Validation accuracy rate is: 1.0\n",
      "The sum of training loss is: 33.1876260659\n",
      "------------------***********-----------------------\n",
      "This is epoch: 81 !\n",
      "Train accuracy rate is: 1.0\n",
      "Validation accuracy rate is: 0.99\n",
      "The sum of training loss is: 0.4829020123\n",
      "------------------***********-----------------------\n",
      "This is epoch: 91 !\n",
      "Train accuracy rate is: 1.0\n",
      "Validation accuracy rate is: 0.99\n",
      "The sum of training loss is: 0.0385477398522\n",
      "Test accuracy rate is: 0.992\n"
     ]
    }
   ],
   "source": [
    "#print classification accuracy\n",
    "with tf.Session() as sess:\n",
    "    model=Memn2n(batch_size,max_sentence_size,max_memory_size,embedding_size,vocabulary_size,optimizer=optimizer)\n",
    "    for i in range(epochs):\n",
    "        np.random.shuffle(batch_index)\n",
    "        cost_sum=0\n",
    "        for start,end in batch_index:\n",
    "            s=train_s[start:end]\n",
    "            q=train_q[start:end]\n",
    "            a=train_a[start:end]\n",
    "            cost=model.train(s,q,a)\n",
    "            cost_sum+=cost\n",
    "        if i%10==0:\n",
    "            train_pre_label=[]\n",
    "            for start in range(0,train_s.shape[0],batch_size):\n",
    "                end=start+batch_size\n",
    "                s=train_s[start:end]\n",
    "                q=train_q[start:end]\n",
    "                train_pre_label+=list(model.predict(s,q))\n",
    "            val_pre_label=model.predict(val_s,val_q)\n",
    "            train_classification_accuracy=metrics.accuracy_score(np.array(train_pre_label),train_answer_label)\n",
    "            val_classification_accuracy=metrics.accuracy_score(val_pre_label,validation_answer_label)\n",
    "            print(\"------------------***********-----------------------\")\n",
    "            print(\"This is epoch: \"+str(i+1)+\" !\")\n",
    "            print(\"Train accuracy rate is: \"+str(train_classification_accuracy))\n",
    "            print(\"Validation accuracy rate is: \"+str(val_classification_accuracy))\n",
    "            print(\"The sum of training loss is: \"+str(cost_sum))\n",
    "    test_pre_label=model.predict(test_s,test_q)\n",
    "    test_classification_accuracy=metrics.accuracy_score(test_pre_label,test_answer_label)\n",
    "    print(\"Test accuracy rate is: \"+str(test_classification_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
