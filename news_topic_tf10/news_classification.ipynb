{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.preprocessing import text\n",
    "import numpy as np\n",
    "import cnn\n",
    "import data_dealer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter embedding_size: 200\n",
      "parameter keep_prob: 0.7\n",
      "parameter batch_size: 300\n",
      "parameter evaluate_step: 50\n",
      "parameter filter_size: 2,3,4\n",
      "parameter train_dev_split_ratio: 0.98\n",
      "parameter topic_num: 12\n",
      "parameter epoch_size: 10\n",
      "parameter filter_num: 3\n",
      "parameter shuffle_input: False\n"
     ]
    }
   ],
   "source": [
    "tf.flags.DEFINE_integer(\"epoch_size\",10,\"Default 10\")\n",
    "tf.flags.DEFINE_integer(\"batch_size\",300,\"Default 300\")\n",
    "tf.flags.DEFINE_integer(\"evaluate_step\",50,\"Evaluate each 50[default] global steps\")\n",
    "tf.flags.DEFINE_integer(\"embedding_size\",200,\"Default 200\")\n",
    "tf.flags.DEFINE_string(\"filter_size\",'2,3,4',\"Default '2,3,4' \")\n",
    "tf.flags.DEFINE_integer(\"filter_num\",3,\"Filter numbers for each kind of filter, default 3\")\n",
    "tf.flags.DEFINE_float(\"keep_prob\",0.7,\"Probability of keep neuron when dropout, default 0.7\")\n",
    "tf.flags.DEFINE_integer(\"topic_num\",12,\"The number of different news topics, it depends on news corpus.\")\n",
    "tf.flags.DEFINE_bool(\"shuffle_input\",False,\"Default False\")\n",
    "tf.flags.DEFINE_float(\"train_dev_split_ratio\",0.98,\"Default 0.01, 98% is training data, 2% is development data\")\n",
    "\n",
    "FLAGS=tf.flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "\n",
    "for para,val in FLAGS.__flags.items():\n",
    "    print(\"parameter %s: %s\"%(para,val))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading news and topic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has beend imported!\n",
      "Sub-data has imported 0.0 percentage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.650 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-data has imported 9.99995750696 percentage\n",
      "Sub-data has imported 19.9999150139 percentage\n",
      "Sub-data has imported 29.9998725209 percentage\n",
      "Sub-data has imported 39.9998300278 percentage\n",
      "Sub-data has imported 49.9997875348 percentage\n",
      "Sub-data has imported 59.9997450418 percentage\n",
      "Sub-data has imported 69.9997025487 percentage\n",
      "Sub-data has imported 79.9996600557 percentage\n",
      "Sub-data has imported 89.9996175627 percentage\n",
      "Sub-data has imported 99.9995750696 percentage\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading news and topic...\")\n",
    "all_urls, all_titles, all_news=data_dealer.import_data()\n",
    "#data is a dictionary, comprised of health, auto, business, it, sports, learning, news, yule 10001 respectively.\n",
    "data=data_dealer.subData(all_urls, all_titles, all_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "health=zip(data['health'],np.ones([10001,1]))\n",
    "auto=zip(data['auto'],2*np.ones([10001,1]))\n",
    "business=zip(data['business'],3*np.ones([10001,1]))\n",
    "x_news=data['health']+data['auto']+data['business']\n",
    "y_label=[0]*10001+[1]*10001+[2]*10001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal length in all news: 1027\n",
      "There are 134044 Chinese vocabulary in all the news corpus.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib import learn\n",
    "max_news_length=max([len(x.split(\" \")) for x in x_news])\n",
    "words_to_num=learn.preprocessing.VocabularyProcessor(max_news_length)\n",
    "print('Maximal length in all news: %s' % max_news_length)\n",
    "x_nums=np.array(list(words_to_num.fit_transform(x_news)))\n",
    "vocabulary_size=len(words_to_num.vocabulary_)\n",
    "print(\"There are %s Chinese vocabulary in all the news corpus.\" % vocabulary_size)\n",
    "#processor.reverse(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FLAGS.shuffle_input=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle input data...\n",
      "Split input data into training and development part...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/m/home/home8/80/shic1/unix/.local/lib/python2.7/site-packages/ipykernel/__main__.py:9: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/m/home/home8/80/shic1/unix/.local/lib/python2.7/site-packages/ipykernel/__main__.py:10: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/m/home/home8/80/shic1/unix/.local/lib/python2.7/site-packages/ipykernel/__main__.py:11: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/m/home/home8/80/shic1/unix/.local/lib/python2.7/site-packages/ipykernel/__main__.py:12: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.shuffle_input:\n",
    "    print(\"Shuffle input data...\")\n",
    "    np.random.seed(1)\n",
    "    new_indices=np.random.permutation(range(len(y_label)))\n",
    "    x_nums=x_nums[new_indices]\n",
    "    y_label=np.array(y_label)[new_indices]\n",
    "\n",
    "print(\"Split input data into training and development part...\")\n",
    "x_train=x_nums[:FLAGS.train_dev_split_ratio*len(y_label),:]\n",
    "y_train=y_label[:FLAGS.train_dev_split_ratio*len(y_label)]\n",
    "x_dev=x_nums[FLAGS.train_dev_split_ratio*len(y_label):,:]\n",
    "y_dev=y_label[FLAGS.train_dev_split_ratio*len(y_label):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29402.94"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]\n",
    "len(x_train[1*FLAGS.batch_size:(1+1)*FLAGS.batch_size])\n",
    "len(x_dev)\n",
    "FLAGS.train_dev_split_ratio*len(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Start training model...--------------------\n",
      "---------------Epoch: 0---------------\n",
      "Train processing: step 1, loss 1.61781108379, accuracy 0.330000013113\n",
      "Train processing: step 2, loss 1.60102701187, accuracy 0.326666653156\n",
      "Train processing: step 3, loss 1.62370955944, accuracy 0.356666654348\n",
      "Train processing: step 4, loss 1.553637743, accuracy 0.370000004768\n",
      "Train processing: step 5, loss 1.41314852238, accuracy 0.396666675806\n",
      "Train processing: step 6, loss 1.46075022221, accuracy 0.370000004768\n",
      "Train processing: step 7, loss 1.53733217716, accuracy 0.370000004768\n",
      "Train processing: step 8, loss 1.325766325, accuracy 0.419999986887\n",
      "Train processing: step 9, loss 1.39533567429, accuracy 0.40000000596\n",
      "Train processing: step 10, loss 1.30168676376, accuracy 0.419999986887\n",
      "Train processing: step 11, loss 1.39774358273, accuracy 0.426666676998\n",
      "Train processing: step 12, loss 1.29785358906, accuracy 0.436666667461\n",
      "Train processing: step 13, loss 1.28034317493, accuracy 0.45666667819\n",
      "Train processing: step 14, loss 1.14983987808, accuracy 0.536666691303\n",
      "Train processing: step 15, loss 1.22745501995, accuracy 0.476666659117\n",
      "Train processing: step 16, loss 1.14987766743, accuracy 0.493333339691\n",
      "Train processing: step 17, loss 1.12542676926, accuracy 0.519999980927\n",
      "Train processing: step 18, loss 1.11619412899, accuracy 0.523333311081\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3e8d63b017a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mx_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0my_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mtrain_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_temp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mcurrent_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcurrent_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_step\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-3e8d63b017a0>\u001b[0m in \u001b[0;36mtrain_one_step\u001b[0;34m(x_batch, y_batch)\u001b[0m\n\u001b[1;32m     18\u001b[0m             feed_dict={cnn.input_news:x_batch,cnn.input_topic:y_batch,\n\u001b[1;32m     19\u001b[0m                        cnn.dropout_keep_probability:FLAGS.keep_prob}\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train processing: step {}, loss {}, accuracy {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/80/shic1/unix/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/80/shic1/unix/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/80/shic1/unix/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/u/80/shic1/unix/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/80/shic1/unix/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"---------------Start training model...--------------------\")\n",
    "gra=tf.Graph()\n",
    "with gra.as_default():\n",
    "    sess=tf.Session()\n",
    "    with sess.as_default():\n",
    "        cnn=cnn.topicCNN(vocabulary_size=vocabulary_size,embedding_size=FLAGS.embedding_size,\n",
    "                         filter_size=map(int,FLAGS.filter_size.split(',')),\n",
    "                         filter_num=FLAGS.filter_num,max_news_size=max_news_length,topic_size=3)\n",
    "        \n",
    "        global_step=tf.Variable(0,name=\"global_step\",trainable=False)\n",
    "        optimizer=tf.train.AdamOptimizer()\n",
    "        gradient_and_variable=optimizer.compute_gradients(cnn.loss)\n",
    "        train_op=optimizer.apply_gradients(gradient_and_variable,global_step=global_step)\n",
    "        \n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        \n",
    "        def train_one_step(x_batch,y_batch):\n",
    "            feed_dict={cnn.input_news:x_batch,cnn.input_topic:y_batch,\n",
    "                       cnn.dropout_keep_probability:FLAGS.keep_prob}\n",
    "            _,step,loss,accuracy=sess.run([train_op,global_step,cnn.loss,cnn.accuracy],feed_dict)\n",
    "            print(\"Train processing: step {}, loss {}, accuracy {}\".format(step,loss,accuracy))\n",
    "        \n",
    "        def dev_one_step(x_batch,y_batch):\n",
    "            feed_dict={cnn.input_news:x_batch,cnn.input_topic:y_batch,\n",
    "                       cnn.dropout_keep_probability:1.0}\n",
    "            step,loss,accuracy=sess.run([global_step,cnn.loss,cnn.accuracy],feed_dict)\n",
    "            print(\"Dev processing: step {}, loss {}, accuracy {}\".format(step,loss,accuracy))\n",
    "        \n",
    "        \n",
    "        for epo in range(FLAGS.epoch_size):\n",
    "            print('---------------Epoch: %s---------------' % epo)\n",
    "            # input data in each epoch is not be permutated!\n",
    "            for i in range(len(y_train)//FLAGS.batch_size):\n",
    "                x_temp=x_train[i*FLAGS.batch_size:(i+1)*FLAGS.batch_size]\n",
    "                y_temp=y_train[i*FLAGS.batch_size:(i+1)*FLAGS.batch_size]\n",
    "                train_one_step(x_temp,y_temp)\n",
    "                current_step=tf.train.global_step(sess,global_step)\n",
    "                if current_step % FLAGS.evaluate_step==0:\n",
    "                    print(\"Evalution start... at step %s\"%current_step)\n",
    "                    dev_one_step(x_dev,y_dev)\n",
    "                    print(\"Evaluation end\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
