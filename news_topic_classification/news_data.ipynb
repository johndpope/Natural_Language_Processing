{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "#pure_data=BeautifulSoup(data,'lxml')\n",
    "def import_data(data_path='/u/80/shic1/unix/Downloads/news_sohusite_xml.dat'):\n",
    "    with open(data_path) as f:\n",
    "        data=f.readlines()\n",
    "    all_urls=data[1::6]\n",
    "    all_titles=data[3::6]\n",
    "    all_news=data[4::6]\n",
    "    print('Data has beend imported!')\n",
    "    return all_urls, all_titles, all_news\n",
    "\n",
    "def convert_chinese(words):\n",
    "    #remove html label\n",
    "    pure_data = re.search('>(.*?)</',words).group(1).decode('GB18030')\n",
    "    #remove all the emotion, punctuations or numbers except chinese words\n",
    "    pure_text = re.sub(u'[^\\u4e00-\\u9fa5]','',pure_data)\n",
    "    #token text to a list of vocabularies\n",
    "    return ' '.join(jieba.cut(pure_text))\n",
    "\n",
    "def extract_url_topic(url):\n",
    "    return re.search('(\\w*?)\\.sohu',url).group(1)\n",
    "\n",
    "#pick health, auto, business, it, sports, learning, news, yule 10000 respectively.\n",
    "def subData(a,b,c):\n",
    "    sub_data=dict()\n",
    "    topics=['health','auto','business','it','sports','learning','news','yule']\n",
    "    for i in topics:\n",
    "        sub_data[i]=[]\n",
    "    count=len(a)//10        \n",
    "    for i in xrange(len(a)):\n",
    "        if (i%count==0):\n",
    "            print('Sub-data has imported %s percentage' % (float(i)/len(a)*100.0))\n",
    "        if (extract_url_topic(a[i]) in topics):\n",
    "            if(len(sub_data[extract_url_topic(a[i])])>10000):\n",
    "                continue\n",
    "            sub_data[extract_url_topic(a[i])].append(convert_chinese(c[i]))\n",
    "    return sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total news number is 1411996\n",
      "Category: health  Number: 23409\n",
      "Category: auto  Number: 138576\n",
      "Category: business  Number: 27489\n",
      "Category: it  Number: 199871\n",
      "Category: sports  Number: 44536\n",
      "Category: travel  Number: 2179\n",
      "Category: learning  Number: 13012\n",
      "Category: cul  Number: 1924\n",
      "Category: news  Number: 86052\n",
      "Category: yule  Number: 50138\n",
      "Category: women  Number: 5882\n",
      "Category: media  Number: 669\n",
      "Category: gongyi  Number: 239\n",
      "Category: roll  Number: 720957\n"
     ]
    }
   ],
   "source": [
    "print('The total news number is %s' % len(a))\n",
    "#'health','auto','business','it','sports','travel','learning','cul','news','yule','women','media','gongyi','roll'\n",
    "# career, mil and house is invalid now!\n",
    "# have no idea what is 'roll'\n",
    "for topic in ['health','auto','business','it','sports','travel','learning','cul','news','yule','women','media','gongyi','roll']:\n",
    "    count=0\n",
    "    for i in xrange(len(a)):\n",
    "        if (extract_url_topic(a[i])==topic):\n",
    "            count+=1\n",
    "    print('Category: {}  Number: {}'.format(topic ,count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\u90fd\\u7075' u'\\u51ac\\u5965\\u4f1a' u'\\u97e9\\u56fd' u'\\u516d'\n",
      " u'\\u91d1\\u4e09\\u94f6' u'\\u4e8c\\u94dc' u'\\u6392\\u540d' u'\\u7b2c\\u516d'\n",
      " u'\\u4e2d\\u56fd' u'\\u4e8c\\u91d1' u'\\u56db\\u94f6\\u4e94\\u94dc'\n",
      " u'\\u6392\\u540d' u'\\u5341\\u56db' u'\\u6309\\u9053\\u7406\\u8bb2'\n",
      " u'\\u4e2d\\u56fd' u'\\u51ac\\u5965' u'\\u519b\\u56e2' u'\\u80fd' u'\\u593a\\u5f97'\n",
      " u'\\u5341' u'\\u4e00\\u679a' u'\\u5956\\u724c' u'\\u5df2\\u7ecf' u'\\u662f'\n",
      " u'\\u5386\\u53f2' u'\\u6700\\u597d' u'\\u6210\\u7ee9' u'\\u4e86']\n",
      "韩国\n"
     ]
    }
   ],
   "source": [
    "print convert_chinese(c[135])\n",
    "print convert_chinese(c[135])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
